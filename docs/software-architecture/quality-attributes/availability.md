---
sidebar_position: 2
---

# Availability

## Principles

A system is available if it's ready to perform a task when needed. This can be thought as _reliability_, and while they seem the same, availability adds the notion of recovery on top of reliability, that is when a system breaks, it can repair itself.

**Availability refers to the ability of a system to mask or repair faults such that the cumulative service outage period does not exceed a required value over a specified time interval**.

Availability is closely related to **security**, in the manner that targeted attacks can bring the system down, making it unavailable for legitimate use. Availability is closely related to **performance**, because it can be hard to tell if the system has failed or if it's just taking a lot of time to carry out it's functions. Availability is also related to safety, which is concerned with keeping the system from entering a hazardous state, and recovering or limiting the system when it does.

**Fundamentally, availability is minimizing service outage time by mitigating system faults**. Failure implies visibility, that is if you can't observer that a failure occurred, you can't really react to it. A failure is a deviation from the system from it's original specifications where the deviation is externally visible. One of the most demanding tasks of building a high-availability, fault-tolerant system is discovering and understanding the nature of the failures that can arise during operation.

A failure cause is called a fault. This distinction lets us discuss more accurately about availability, a system can recover from a fault, but if it fails to do that, then we have a failure on the system.

When thinking about availability, you should think about what will make your system fail, how likely that is to occur, and that there will be some time needed to repair it.

There's a formula to calculate a systems availability that's based on the probability that the system will provided it's required services in a bounded period of time, it takes into account the mean time between failures, and the mean time to repair. Usually the results of this formula is a bunch of nines (99.99%) indicating availability. A system is said to have high-availability if it has 5 nines, that is 99.999% of availability over a period of time. It's important to note that scheduled down times are not accounted as service outages.

Fault correlation logic will categorize a fault according to it's severity (critical, major or minor), and service impact in order to provide the system operator with timely and secure system status, and allow the appropriate repair strategy to be employed.

When designing a high-availability, or safety-critical system you should plan for failure, because it's going to happen. Methods for doing that are Hazard Analysis and Fault Tree Analysis.

## General Scenario

- _Source of stimulus_: We differentiate between internal and external origins of faults because the reaction may be different depending on that.
- _Stimulus_: A fault of one of the following classes occurs:
  - _Omission_: A component fails to respond to an input
  - _Crash_: The component repeatedly suffers omission faults
  - _Timing_: A component responds but the response is early or late
  - _Response_: A component responds with the incorrect value
- _Artifact_: This specifies the source that must be highly available, such as a processor, communication channel, process, or storage.
- _Environment_: The state of the system when the fault or failure occurs may also affect the desired system response.
- _Response_: There are a number of possible reactions to a system fault. First, the fault must be detected and isolated before any other response is possible. After detected, the system must recover from it.
- _Response Measure_: The response measure can specify an availability percentage, or it can specify the time to detect the fault, time to repair the fault, times or time intervals during which the system must be available, or the duration for which the system must be available

| Portion of Scenario | Possible Values                                                                                                                                                                                                                                                                                                                                                                    |
| ------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Source              | Internal/external: people, hardware, software, physical infrastructure, physical environment                                                                                                                                                                                                                                                                                       |
| Stimulus            | Fault: omission, crash, inc-orrect timing, incorrect response Processors, communication channels, persistent storage, processes                                                                                                                                                                                                                                                    |
| Stimulus Artifact   | Processors, communication channels, persistent storage, processes                                                                                                                                                                                                                                                                                                                  |
| Environment         | Normal operation, startup, shutdown, repair mode, degraded operation, over1oaded operation                                                                                                                                                                                                                                                                                         |
| Response            | Prevent the fault from becoming a failure Detect the fault: <ul><li>Log the fault</li><li>Notify appropriate entities (people or systems)</li></ul>Recover from the fault: <ul><li> Disable source of events causing the fault</li><li> Be temporarily unavailable while repair is being effected</li><li> Fix or mask the fault/failure or contain the damage it causes</li></ul> |
| Response Measure    | Time or time interval when the system must be available Availability percentage (e.g., 99.999%) Time to detect the fault Time to repair the fault Time or time interval in which system can be in degraded mode Proportion (e.g., 99%) or rate (e.g., up to 100 per second) of a certain class of faults that the system prevents, or handles without failing                      |

## Tactics

Availability tactics may be categorized as addressing one of these three categories: fault detection, fault recovery, and fault prevention.

Further, these tactics will be provided for you by a software infrastructure, such as a middleware package, so your job as an architect is often one of choosing and assessing (rather than implementing) the right availability tactics and the right combination of tactics.

### Detect Faults

Before any system can take action regarding a fault, the presence of the fault
must be detected or anticipated. Tactics in this category include the following:

- **Ping/echo** refers to an asynchronous request/response message pair exchanged between nodes, used to determine reachability and the round-trip delay through the associated network path. But the echo also determines that the pinged component is alive and responding correctly. The ping is often sent by a system monitor. Ping/echo requires a time threshold to be set; this threshold tells the pinging component how long to wait for the echo before considering the pinged component to have failed (“timed out”). Standard implementations of ping/echo are available for nodes interconnected via IP.
- **Monitor**. A monitor is a component that is used to monitor the state ofhealth of various other parts of the system: processors, processes, I/O, memory, and so on. A system monitor can detect failure or congestion in the network or other shared resources, such as from a denial-of-service attack. It orchestrates software using other tactics in this category to detect malfunctioning components. For example, the system monitor can initiate self-tests, or be the component that detects faulty time stamps or missed heartbeats.
- **Heartbeat** is a fault detection mechanism that employs a periodic message
  exchange between a system monitor and a process being monitored. A
  special case of heartbeat is when the process being monitored periodically
  resets the watchdog timer in its monitor to prevent it from expiring and thus
  signaling a fault. For systems where scalability is a concern, transport and
  processing overhead can be reduced by piggybacking heartbeat messages
  on to other control messages being exchanged between the process being
  monitored and the distributed system controller. The big difference between
  heartbeat and ping/echo is who holds the responsibility for initiating the
  health check—the monitor or the component itself.
- **Time stamp**. This tactic is used to detect incorrect sequences of events, primarily in distributed message-passing systems. A time stamp of an event can be established by assigning the state of a local clock to the event immediately after the event occurs. Simple sequence numbers can also be used for this purpose, if time information is not important.
- **Sanity checking** checks the validity or reasonableness of specific operations or outputs of a component. This tactic is typically based on a knowledge of the internal design, the state of the system, or the nature of the information under scrutiny. It is most often employed at interfaces, to examine a specific information flow.
- **Condition monitoring** involves checking conditions in a process or device, or validating assumptions made during the design. By monitoring conditions, this tactic prevents a system from producing faulty behavior. The computation of checksums is a common example of this tactic. However, the monitor must itself be simple (and, ideally, provable) to ensure that it does not introduce new software errors.
- **Voting**. The most common realization of this tactic is referred to as triple
  modular redundancy (TMR), which employs three components that do thesame thing, each of which receives identical inputs, and forwards their output to voting logic, used to detect any inconsistency among the three output states. Faced with an inconsistency, the voter reports a fault. It must also decide what output to use. It can let the majority rule, or choose some computed average of the disparate outputs. This tactic depends critically on thevoting logic, which is usually realized as a simple, rigorously reviewed and tested singleton so that the probability of error is low.
  - Replication is the simplest form of voting; here, the components are exact clones of each other. Having multiple copies of identical components can be effective in protecting against random failures of hardware, but this cannot protect against design or implementation errors, in hardware or software, because there is no form of diversity embedded in this tactic.
  - Functional redundancy is a form of voting intended to address the issue of common-mode failures (design or implementation faults) in hardware or software components. Here, the components must always give the same output given the same input, but they are diversely designed and diversely implemented.
  - Analytic redundancy permits not only diversity among components’ private sides, but also diversity among the components’ inputs and outputs. This tactic is intended to tolerate specification errors by using separate requirement specifications. In embedded systems, analytic redundancy also helps when some input sources are likely to be unavailable at times. For example, avionics programs have multiple ways to compute aircraft altitude, such as using barometric pressure, the radar altimeter, a geometrically using the straight-line distance and look-down angle of a point ahead on the ground. The voter mechanism used with analytic redundancy needs be more sophisticated than just letting majority rule or computing a simple average. It may have to understand which sensors are currently reliable or not, and it may be asked to produce a higher-fidelity value than any individual component can, by blending and smoothing individual values over time.
- **Exception detection** refers to the detection of a system condition that alters the normal flow of execution. The exception detection tactic can be further refined:
  - System exceptions will vary according to the processor hardware architecture employed and include faults such as divide by zero, bus and address faults, illegal program instructions, and so forth.
  - The parameter fence tactic incorporates an a priori data pattern (such as 0xDEADBEEF) placed immediately after any variable-length parameters of an object. This allows for runtime detection of overwriting the memory allocated for the object’s variable-length parameters.
  - Parameter typing employs a base class that defines functions that add, find, and iterate over type-length-value (TLV) formatted message parameter Derived classes use the base class functions to implement functions that provide parameter typing according to each parameter’s structure. Use of strong typing to build and parse messages results in higher availabili than implementations that simply treat messages as byte buckets. Of course, all design involves tradeoffs. When you employ strong typing, you typically trade higher availability against ease of evolution.
  - Timeout is a tactic that raises an exception when a component detects that it or another component has failed to meet its timing constraints. For example, a component awaiting a response from another component can raise an exception if the wait time exceeds a certain value.
- **Self-test.** Components (or, more likely, whole subsystems) can run procedures to test themselves for correct operation. Self-test procedures can be initiated by the component itself, or invoked from time to time by a system monitor. These may involve employing some of the techniques found in condition monitoring, such as checksums.

### Recover from Faults

Recover-from-faults tactics are refined into preparation-and-repair tactics and
reintroduction tactics. The latter are concerned with reintroducing a failed (but
rehabilitated) component back into normal operation.
Preparation-and-repair tactics are based on a variety of combinations of retrying a computation or introducing redundancy. They include the following:

- **Active redundancy** (hot spare). This refers to a configuration where all of the nodes (active or redundant spare) in a protection group2 receive and process identical inputs in parallel, allowing the redundant spare(s) to maintai synchronous state with the active node(s). Because the redundant spare possesses an identical state to the active processor, it can take over from a failed component in a matter of milliseconds. The simple case of one active node and one redundant spare node is commonly referred to as 1+1 (“one plus one”) redundancy. Active redundancy can also be used for facilities protection, where active and standby network links are used to ensure highly available network connectivity.
- **Passive redundancy** (warm spare). This refers to a configuration where only the active members of the protection group process input traffic; one of their duties is to provide the redundant spare(s) with periodic state updates. Because the state maintained by the redundant spares is only loosely coupled with that of the active node(s) in the protection group (with the looseness of the coupling being a function of the checkpointing mechanism employed between active and redundant nodes), the redundant nodes are referred to as warm spares. Depending on a system’s availability requirements, passive redundancy provides a solution that achieves a balance between the more highly available but more compute-intensive (and expensive) active redundancy tactic and the less available but significantly less complex cold spare tactic (which is also significantly cheaper).
- **Spare** (cold spare). Cold sparing refers to a configuration where the redundant spares of a protection group remain out of service until a fail-over occurs, at which point a power-on-reset procedure is initiated on the redundant spare prior to its being placed in service. Due to its poor recovery performance, cold sparing is better suited for systems having only high-reliability (MTBF) requirements as opposed to those also having high-availability requirements.
- **Exception handling**. Once an exception has been detected, the system must handle it in some fashion. The easiest thing it can do is simply to crash, but of course that’s a terrible idea from the point of availability, usability, testability, and plain good sense. There are much more productive possibilities. The mechanism employed for exception handling depends largely on the programming environment employed, ranging from simple function return codes (error codes) to the use of exception classes that contain information helpful in fault correlation, such as the name of the exception thrown, the origin of the exception, and the cause of the exception thrown. Software can then use this information to mask the fault, usually by correcting the cause of the exception and retrying the operation.
- **Rollback**. This tactic permits the system to revert to a previous known good state, referred to as the “rollback line”—rolling back time—upon the detection of a failure. Once the good state is reached, then execution can continue. This tactic is often combined with active or passive redundancy tactics so that after a rollback has occurred, a standby version of the failed component is promoted to active status. Rollback depends on a copy of a previous good state (a checkpoint) being available to the components that are rolling back. Checkpoints can be stored in a fixed location and updated at regular intervals, or at convenient or significant times in the processing, such as at the completion of a complex operation.
- **Software upgrade** is another preparation-and-repair tactic whose goal is to achieve in-service upgrades to executable code images in a non-service-affecting manner. This may be realized as a function patch, a class patch, or a hitless in-service software upgrade (ISSU). A function patch is used in procedural programming and employs an incremental linker/loader to store an updated software function into a pre-allocated segment of target memory. The new version of the software function will employ the entry and exit points of the deprecated function. Also, upon loading the new software function, the symbol table must be updated and the instruction cache invalidated. The class patch tactic is applicable for targets executing object-oriented code, where the class definitions include a back-door mechanism that enables the runtime addition of member data and functions. Hitless in-service software upgrade leverages the active redundancy or passive redundancy tactics to achieve non-service-affecting upgrades to software and associated schema. In practice, the function patch and class patch are used to deliver bug fixes, while the hitless in-service software upgrade is used to deliver new features and capabilities
- **Retry**. The retry tactic assumes that the fault that caused a failure is transient and retrying the operation may lead to success. This tactic is used in networks and in server farms where failures are expected and common. There should be a limit on the number of retries that are attempted before a permanent failure is declared.
- **Ignore faulty behavior**. This tactic calls for ignoring messages sent from a particular source when we determine that those messages are spurious. For example, we would like to ignore the messages of an external component launching a denial-of-service attack by establishing Access Control List filters, for example.
- The **degradation** tactic maintains the most critical system functions in the presence of component failures, dropping less critical functions. This is done in circumstances where individual component failures gracefully reduce system functionality rather than causing a complete system failure.
- **Reconfiguration** attempts to recover from component failures by reassigning responsibilities to the (potentially restricted) resources left functioning,while maintaining as much functionality as possible.

Reintroduction is where a failed component is reintroduced after it has been
corrected. Reintroduction tactics include the following:

- The **shadow** tactic refers to operating a previously failed or in-service upgraded component in a “shadow mode” for a predefined duration of time prior to reverting the component back to an active role. During this duration its behavior can be monitored for correctness and it can repopulate its state incrementally.
- **State resynchronization** is a reintroduction partner to the active redundancy and passive redundancy preparation-and-repair tactics. When used alongside the active redundancy tactic, the state resynchronization occurs organically, because the active and standby components each receive and process identical inputs in parallel. In practice, the states of the active and standby components are periodically compared to ensure synchronization. This comparison may be based on a cyclic redundancy check calculation (checksum) ‎or, for systems providing safety-critical services, a message digest calculation (a one-way hash function). When used alongside the passive redundancy (warm spare) tactic, state resynchronization is based solely on periodic state information transmitted from the active component(s) to the standby component(s), typically via checkpointing. A special case of this tactic is found in stateless services, whereby any resource can handle a request from another (failed) resource
- **Escalating restart** is a reintroduction tactic that allows the system to recover from faults by varying the granularity of the component(s) restarted and minimizing the level of service affected. For example, consider a system that supports four levels of restart, as follows. The lowest level of restart (call it Level 0), and hence having the least impact on services, employs passive redundancy (warm spare), where all child threads of the faulty component are killed and recreated. In this way, only data associated with the child threads is freed and reinitialized. The next level of restart (Level 1) frees and reinitializes all unprotected memory (protected memory would remain untouched). The next level of restart (Level 2) frees and reinitializes all memory, both protected and unprotected, forcing all applications to reload and reinitialize. And the final level of restart (Level 3) would involve completely reloading and reinitializing the executable image and associated data segments. Support for the escalating restart tactic is particularly useful for the concept of graceful degradation, where a system is able to degrade the services it provides while maintaining support for mission-critical or safety-critical applications.
- **Non-stop forwarding (NSF)** is a concept that originated in router design. In this design functionality is split into two parts: supervisory, or control plane (which manages connectivity and routing information), and data plane (which does the actual work of routing packets from sender to receiver). If a router experiences the failure of an active supervisor, it can continue forwarding packets along known routes—with neighboring routers—while the routing protocol information is recovered and validated. When the control plane is restarted, it implements what is sometimes called “graceful restart,” incrementally rebuilding its routing protocol database even as the data plane continues to operate.

### Prevent Faults

Instead of detecting faults and then trying to recover from them, what if your system could prevent them from occurring in the first place? Although this sounds
like some measure of clairvoyance might be required, it turns out that in many
cases it is possible to do just that.

- **Removal from service**. This tactic refers to temporarily placing a system component in an out-of-service state for the purpose of mitigating potential system failures. One example involves taking a component of a system out of service and resetting the component in order to scrub latent faults (such as memory leaks, fragmentation, or soft errors in an unprotected cache) before the accumulation of faults affects service (resulting in system failure). Another term for this tactic is software rejuvenation.
- **Transactions**. Systems targeting high-availability services leverage transactional semantics to ensure that asynchronous messages exchanged between distributed components are atomic, consistent, isolated, and durable. These four properties are called the “ACID properties.” The most common realization of the transactions tactic is “two-phase commit” (a.k.a. 2PC) protocol. This tactic prevents race conditions caused by two processes attempting to update the same data item.
- **Predictive model**. A predictive model, when combined with a monitor, is employed to monitor the state of health of a system process to ensure that the system is operating within its nominal operating parameters, and to take corrective action when conditions are detected that are predictive of likely future faults. The operational performance metrics monitored are used to predict the onset of faults; examples include session establishment rate (in an HTTP server), threshold crossing (monitoring high and low water marks for some constrained, shared resource), or maintaining statistics for process state (in service, out of service, under maintenance, idle), message queue length statistics, and so on.
- Exception prevention. This tactic refers to techniques employed for the purpose of preventing system exceptions from occurring. The use of exception classes, which allows a system to transparently recover from system exceptions, was discussed previously. Other examples of exception prevention include abstract data types, such as smart pointers, and the use of wrappers to prevent faults, such as dangling pointers and semaphore access violations from occurring. Smart pointers prevent exceptions by doing bounds checking on pointers, and by ensuring that resources are automatically deallocated when no data refers to it. In this way resource leaks are avoided.
- **Increase competence set**. A program’s competence set is the set of states inwhich it is “competent” to operate. For example, the state when the denominator is zero is outside the competence set of most divide programs. When a component raises an exception, it is signaling that it has discovered itself to be outside its competence set; in essence, it doesn’t know what to do and is throwing in the towel. Increasing a component’s competence set means designing it to handle more cases—faults—as part of its normal operation. For example, a component that assumes it has access to a shared resource might throw an exception if it discovers that access is blocked. Another component might simply wait for access, or return immediately with an indication that it will complete its operation on its own the next time it does have access. In this example, the second component has a larger competence set than the first.

## Checklist

| Category                             | Checklist                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |
| ------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Allocation of Responsibilities       | Determine the system responsibilities that need to be highly available. Within those responsibilities, ensure that additional responsibilities have been allocated to detect an omission, crash, incorrect timing, or incorrect response. Additionally, ensure that there are responsibilities to do the following: <ul><li> Log the fault</li><li> Notify appropriate entities (people or systems)</li><li> Disable the source of events causing the fault</li><li> Be temporarily unavailable</li><li> Fix or mask the fault/failure</li><li> Operate in a degraded mode </li></ul>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |
| Coordination Model                   | Determine the system responsibilities that need to be highly available. With respect to those responsibilities, do the following: <ul><li> Ensure that coordination mechanisms can detect an omission, crash, incorrect timing, or incorrect response. Consider, for example, whether guaranteed delivery is necessary. Will the coordination work under conditions of degraded communication?</li><li> Ensure that coordination mechanisms enable the logging of the fault, notification of appropriate entities, disabling of the source of the events causing the fault, fixing or masking the fault, or operating in a degraded mode.</li><li> Ensure that the coordination model supports the replacement of the artifacts used (processors, communications channels, persistent storage, and processes). For example, does replacement of a server allow the system to continue to operate?</li><li> Determine if the coordination will work under conditions of degraded communication, at startup/shutdown, in repair mode, or under overloaded operation. For example, how much lost information can the coordination model withstand and with what consequences?</li></ul> |
| Data Model                           | Determine which portions of the system need to be highly available. Within those portions, determine which data abstractions, along with their operations or their properties, could cause a fault of omission, a crash, incorrect timing behavior, or an incorrect response. For those data abstractions, operations, and properties, ensure that they can be disabled, be temporarily unavailable, or be fixed or masked in the event of a fault. For example, ensure that write requests are cached if a server is temporarily unavailable and performed when the server is returned to service.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |
| Mapping among Architectural Elements | Determine which artifacts (processors, communication channels, persistent storage, or processes) may produce a fault: omission, crash, incorrect timing, or incorrect response. Ensure that the mapping (or remapping) of architectural elements is flexible enough to permit the recovery from the fault. This may involve a consideration of the following:<ul><li> Which processes on failed processors need to be reassigned at runtime </li><li> Which processors, data stores, or communication channels can be activated or reassigned at runtime </li><li> How data on failed processors or storage can be served by replacement units</li><li> How quickly the system can be reinstalled based on the units of delivery provided </li> <li> How to (re)assign runtime elements to processors, communication channels, and data stores </li><li> When employing tactics that depend on redundancy of functionality, the mapping from modules to redundant components is important. For example, it is possible to write one module that contains code appropriate for both the active component and backup components in a protection group. </li></ul>                      |
| Resource Management                  | Determine what critical resources are necessary to continue operating in the presence of a fault: omission, crash, incorrect timing, or incorrect response. Ensure there are sufficient remaining resources in the event of a fault to log the fault; notify appropriate entities (people or systems); disable the source of events causing the fault; be temporarily unavailable; fix or mask the fault/failure; operate normally, in startup, shutdown, repair mode, degraded operation, and overloaded operation. Determine the availability time for critical resources, what critical resources must be available during specified time intervals, time intervals during which the critical resources may be in a degraded mode, and repair time for critical resources. Ensure that the critical resources are available during these time intervals. For example, ensure that input queues are large enough to buffer anticipated messages if a server fails so that the messages are not permanently lost.                                                                                                                                                                   |
| Binding Time                         | Determine how and when architectural elements are bound. If late binding is used to alternate between components that can themselves be sources of faults (e.g., processes, processors, communication channels), ensure the chosen availability strategy is sufficient to cover faults introduced by all sources. For example:<ul><li> If late binding is used to switch between artifacts such as processors that will receive or be the subject of faults, will the chosen fault detection and recovery mechanisms work for all possible bindings?</li><li> If late binding is used to change the definition or tolerance of what constitutes a fault (e.g., how long a process can go without responding before a fault is assumed), is the recovery strategy chosen sufficient to handle all cases? For example, if a fault is flagged after 0.1 milliseconds, but the recovery mechanism takes 1.5 seconds to work, that might be an unacceptable mismatch.</li><li> What are the availability characteristics of the late binding mechanism itself? Can it fail?</li></ul>                                                                                                     |
| Choice of Technolofy                 | Determine the available technologies that can (help) detect faults, recover from faults, or reintroduce failed components. Determine what technologies are available that help the response to a fault (e.g., event loggers). Determine the availability characteristics of chosen technologies themselves: What faults can they recover from? What faults might they introduce into the system?                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |
